{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Audio Processing\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import pyAudioAnalysis\n",
    "from pyAudioAnalysis import audioTrainTest as aT\n",
    "from pyAudioAnalysis import audioBasicIO\n",
    "from pyAudioAnalysis import MidTermFeatures\n",
    "\n",
    "# Numerical Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# System utilities\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion (02): Encoded as:\n",
    "# 01 = neutral\n",
    "# 02 = calm\n",
    "# 03 = happy\n",
    "# 04 = sad\n",
    "# 05 = angry\n",
    "# 06 = fearful\n",
    "# 07 = disgust\n",
    "# 08 = surprised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     file_path  emotion  actor\n",
      "0   data/audio/actor1/03-01-08-02-02-01-01.wav        8      1\n",
      "1   data/audio/actor1/03-01-08-01-01-01-01.wav        8      1\n",
      "2   data/audio/actor1/03-01-05-01-02-01-01.wav        5      1\n",
      "3   data/audio/actor1/03-01-06-01-02-02-01.wav        6      1\n",
      "4   data/audio/actor1/03-01-06-02-01-02-01.wav        6      1\n",
      "5   data/audio/actor1/03-01-05-02-01-01-01.wav        5      1\n",
      "6   data/audio/actor1/03-01-07-01-01-01-01.wav        7      1\n",
      "7   data/audio/actor1/03-01-04-01-01-02-01.wav        4      1\n",
      "8   data/audio/actor1/03-01-04-02-02-02-01.wav        4      1\n",
      "9   data/audio/actor1/03-01-07-02-02-01-01.wav        7      1\n",
      "10  data/audio/actor1/03-01-03-02-02-02-01.wav        3      1\n",
      "11  data/audio/actor1/03-01-03-01-01-02-01.wav        3      1\n",
      "12  data/audio/actor1/03-01-02-02-01-01-01.wav        2      1\n",
      "13  data/audio/actor1/03-01-01-01-02-02-01.wav        1      1\n",
      "14  data/audio/actor1/03-01-02-01-02-01-01.wav        2      1\n",
      "15  data/audio/actor1/03-01-03-02-01-01-01.wav        3      1\n",
      "16  data/audio/actor1/03-01-03-01-02-01-01.wav        3      1\n",
      "17  data/audio/actor1/03-01-02-02-02-02-01.wav        2      1\n",
      "18  data/audio/actor1/03-01-02-01-01-02-01.wav        2      1\n",
      "19  data/audio/actor1/03-01-01-01-01-01-01.wav        1      1\n"
     ]
    }
   ],
   "source": [
    "# Define data path\n",
    "data_path = \"data/audio/actor1\"\n",
    "files = []\n",
    "\n",
    "# Iterate through each file and extract features\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith(\".wav\"):\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        # Parse labels from filename\n",
    "        parts = file.split(\"-\")\n",
    "        emotion = int(parts[2])  # Extract emotion from filename\n",
    "        actor = int(parts[-1].split(\".\")[0])  # Extract actor ID\n",
    "        files.append({\"file_path\": file_path, \"emotion\": emotion, \"actor\": actor})\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame(files)\n",
    "print(data.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will give you the exact type of emotion the audio is displaying\n",
    "\n",
    "emotion_dict = {\n",
    "    1: \"neutral\",\n",
    "    2: \"calm\",\n",
    "    3: \"happy\",\n",
    "    4: \"sad\",\n",
    "    5: \"angry\",\n",
    "    6: \"fearful\",\n",
    "    7: \"disgust\",\n",
    "    8: \"surprised\"\n",
    "}\n",
    "\n",
    "data[\"emotion_label\"] = data[\"emotion\"].map(emotion_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    file_path  emotion  actor emotion_label\n",
      "0  data/audio/actor1/03-01-08-02-02-01-01.wav        8      1     surprised\n",
      "1  data/audio/actor1/03-01-08-01-01-01-01.wav        8      1     surprised\n",
      "2  data/audio/actor1/03-01-05-01-02-01-01.wav        5      1         angry\n",
      "3  data/audio/actor1/03-01-06-01-02-02-01.wav        6      1       fearful\n",
      "4  data/audio/actor1/03-01-06-02-01-02-01.wav        6      1       fearful\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    file_path  emotion  actor emotion_label  \\\n",
      "0  data/audio/actor1/03-01-08-02-02-01-01.wav        8      1     surprised   \n",
      "1  data/audio/actor1/03-01-08-01-01-01-01.wav        8      1     surprised   \n",
      "2  data/audio/actor1/03-01-05-01-02-01-01.wav        5      1         angry   \n",
      "3  data/audio/actor1/03-01-06-01-02-02-01.wav        6      1       fearful   \n",
      "4  data/audio/actor1/03-01-06-02-01-02-01.wav        6      1       fearful   \n",
      "\n",
      "                                            features  \n",
      "0  [-514.731, 62.937397, -6.146049, 10.8779125, 0...  \n",
      "1  [-602.8393, 72.09309, -0.67978925, 11.220813, ...  \n",
      "2  [-506.93576, 63.804733, -2.4667234, 16.526533,...  \n",
      "3  [-527.7185, 80.91389, -7.1170683, 21.611485, 7...  \n",
      "4  [-330.14752, 54.85853, -23.322374, -1.3208342,...  \n"
     ]
    }
   ],
   "source": [
    "# used to gather feautrues that will be used on the X test model\n",
    "def extract_features(file_path):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(file_path, duration=2.5, offset=0.5)\n",
    "    # Extract MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    # Compute mean of each coefficient\n",
    "    mfccs_mean = mfccs.mean(axis=1)\n",
    "    return mfccs_mean\n",
    "\n",
    "# Add features to DataFrame\n",
    "data[\"features\"] = data[\"file_path\"].apply(extract_features)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare features and labels\n",
    "X = np.array(data[\"features\"].tolist())\n",
    "y = data[\"emotion\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.00      0.00      0.00         1\n",
      "        calm       0.67      1.00      0.80         2\n",
      "       happy       0.00      0.00      0.00         1\n",
      "         sad       0.25      1.00      0.40         1\n",
      "       angry       0.50      1.00      0.67         1\n",
      "     fearful       0.00      0.00      0.00         1\n",
      "     disgust       1.00      1.00      1.00         1\n",
      "   surprised       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.43      0.56      0.44        12\n",
      "weighted avg       0.59      0.58      0.53        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=list(emotion_dict.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the Model Used Chat to get a simple paragraph below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model is trying to recognize emotions like \"neutral,\" \"calm,\" and \"happy,\" but it’s only getting some of them right. It’s great at recognizing \"disgust\" and okay with \"calm\" and \"angry,\" but it completely failed to identify \"neutral,\" \"happy,\" and \"fearful.\" Overall, it got 58% of things correct, which isn’t bad but shows room for improvement. The model struggles with emotions that might sound similar or didn’t have enough examples during training. To make it better, you might need more balanced data or better features to help the model understand tricky emotions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
