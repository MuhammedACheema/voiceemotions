{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Audio Processing\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import pyAudioAnalysis\n",
    "from pyAudioAnalysis import audioTrainTest as aT\n",
    "from pyAudioAnalysis import audioBasicIO\n",
    "from pyAudioAnalysis import MidTermFeatures\n",
    "\n",
    "# Numerical Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# System utilities\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# will be used to save the model to be used to make future predictions\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion (02): Encoded as:\n",
    "# 01 = neutral\n",
    "# 02 = calm\n",
    "# 03 = happy\n",
    "# 04 = sad\n",
    "# 05 = angry\n",
    "# 06 = fearful\n",
    "# 07 = disgust\n",
    "# 08 = surprised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     file_path  emotion  actor\n",
      "0   data/audio/actor1/03-01-06-01-02-02-02.wav        6      2\n",
      "1   data/audio/actor1/03-01-05-01-02-01-16.wav        5     16\n",
      "2   data/audio/actor1/03-01-08-01-01-01-14.wav        8     14\n",
      "3   data/audio/actor1/03-01-06-01-02-02-16.wav        6     16\n",
      "4   data/audio/actor1/03-01-05-01-02-01-02.wav        5      2\n",
      "5   data/audio/actor1/03-01-01-01-02-02-06.wav        1      6\n",
      "6   data/audio/actor1/03-01-02-01-02-01-12.wav        2     12\n",
      "7   data/audio/actor1/03-01-01-01-02-02-12.wav        1     12\n",
      "8   data/audio/actor1/03-01-02-01-02-01-06.wav        2      6\n",
      "9   data/audio/actor1/03-01-02-02-01-01-06.wav        2      6\n",
      "10  data/audio/actor1/03-01-02-02-01-01-12.wav        2     12\n",
      "11  data/audio/actor1/03-01-06-02-01-02-16.wav        6     16\n",
      "12  data/audio/actor1/03-01-05-02-01-01-02.wav        5      2\n",
      "13  data/audio/actor1/03-01-08-02-02-01-14.wav        8     14\n",
      "14  data/audio/actor1/03-01-06-02-01-02-02.wav        6      2\n",
      "15  data/audio/actor1/03-01-05-02-01-01-16.wav        5     16\n",
      "16  data/audio/actor1/03-01-05-01-01-01-22.wav        5     22\n",
      "17  data/audio/actor1/03-01-08-01-02-01-20.wav        8     20\n",
      "18  data/audio/actor1/03-01-06-01-01-02-22.wav        6     22\n",
      "19  data/audio/actor1/03-01-08-01-02-01-08.wav        8      8\n"
     ]
    }
   ],
   "source": [
    "# Define data path\n",
    "data_path = \"data/audio/actor1\"\n",
    "files = []\n",
    "\n",
    "# Iterate through each file and extract features\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith(\".wav\"):\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        # Parse labels from filename\n",
    "        parts = file.split(\"-\")\n",
    "        emotion = int(parts[2])  # Extract emotion from filename\n",
    "        actor = int(parts[-1].split(\".\")[0])  # Extract actor ID\n",
    "        files.append({\"file_path\": file_path, \"emotion\": emotion, \"actor\": actor})\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame(files)\n",
    "print(data.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will give you the exact type of emotion the audio is displaying\n",
    "\n",
    "emotion_dict = {\n",
    "    1: \"neutral\",\n",
    "    2: \"calm\",\n",
    "    3: \"happy\",\n",
    "    4: \"sad\",\n",
    "    5: \"angry\",\n",
    "    6: \"fearful\",\n",
    "    7: \"disgust\",\n",
    "    8: \"surprised\"\n",
    "}\n",
    "\n",
    "data[\"emotion_label\"] = data[\"emotion\"].map(emotion_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    file_path  emotion  actor emotion_label\n",
      "0  data/audio/actor1/03-01-06-01-02-02-02.wav        6      2       fearful\n",
      "1  data/audio/actor1/03-01-05-01-02-01-16.wav        5     16         angry\n",
      "2  data/audio/actor1/03-01-08-01-01-01-14.wav        8     14     surprised\n",
      "3  data/audio/actor1/03-01-06-01-02-02-16.wav        6     16       fearful\n",
      "4  data/audio/actor1/03-01-05-01-02-01-02.wav        5      2         angry\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    file_path  emotion  actor emotion_label  \\\n",
      "0  data/audio/actor1/03-01-06-01-02-02-02.wav        6      2       fearful   \n",
      "1  data/audio/actor1/03-01-05-01-02-01-16.wav        5     16         angry   \n",
      "2  data/audio/actor1/03-01-08-01-01-01-14.wav        8     14     surprised   \n",
      "3  data/audio/actor1/03-01-06-01-02-02-16.wav        6     16       fearful   \n",
      "4  data/audio/actor1/03-01-05-01-02-01-02.wav        5      2         angry   \n",
      "\n",
      "                                            features  \n",
      "0  [-484.8887, 38.065163, -37.226795, -2.0721314,...  \n",
      "1  [-441.4606, 51.2628, -7.4304695, 3.497119, -16...  \n",
      "2  [-617.22217, 55.499153, -9.51583, 9.527895, -1...  \n",
      "3  [-486.03268, 51.385868, -8.118707, 5.6450877, ...  \n",
      "4  [-476.39212, 65.21153, -18.103632, 3.509009, -...  \n"
     ]
    }
   ],
   "source": [
    "# used to gather feautrues that will be used on the X test model\n",
    "def extract_features(file_path):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(file_path, duration=2.5, offset=0.5)\n",
    "    # Extract MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    # Compute mean of each coefficient\n",
    "    mfccs_mean = mfccs.mean(axis=1)\n",
    "    mfccs_std = mfccs.std()\n",
    "\n",
    "    total = mfccs_mean + mfccs_std\n",
    "    \n",
    "    return mfccs_mean\n",
    "\n",
    "# Add features to DataFrame\n",
    "data[\"features\"] = data[\"file_path\"].apply(extract_features)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare features and labels\n",
    "X = np.array(data[\"features\"].tolist())\n",
    "y = data[\"emotion\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.70      0.41      0.52        17\n",
      "        calm       0.43      0.71      0.54        28\n",
      "       happy       0.65      0.59      0.62        37\n",
      "         sad       0.65      0.49      0.56        45\n",
      "       angry       0.80      0.78      0.79        50\n",
      "     fearful       0.56      0.61      0.58        33\n",
      "     disgust       0.45      0.58      0.51        33\n",
      "   surprised       0.70      0.58      0.63        45\n",
      "\n",
      "    accuracy                           0.61       288\n",
      "   macro avg       0.62      0.59      0.59       288\n",
      "weighted avg       0.63      0.61      0.61       288\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['emotion_model']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=list(emotion_dict.values())))\n",
    "\n",
    "joblib.dump(clf, 'emotion_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the Model Used Chat to get a simple paragraph below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data evaluates a classification model's performance in predicting emotions, showing metrics like precision, recall, and F1-score for each class (e.g., *happy, sad, angry*). Accuracy (0.61) indicates the model correctly predicted 61% of the 288 samples. Macro averages (precision: 0.60, recall: 0.60, F1: 0.59) show the unweighted mean performance across all classes, treating each equally. Weighted averages (precision: 0.62, recall: 0.61, F1: 0.61) account for class sizes, giving more weight to larger classes. The model performs best on \"angry\" (F1: 0.77) and struggles with \"neutral\" and \"disgust.\" Overall, the model has moderate performance, with room for improvement, particularly in underrepresented classes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
